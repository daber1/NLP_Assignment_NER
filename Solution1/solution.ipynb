{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KTICtNOBfzrx"
   },
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ru_core_news_md\n",
    "from tqdm import tqdm\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "8hGwMn558YPS",
    "outputId": "fd1c2e88-9c82-4ff3-d041-c930d9b292ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ru-core-news-md==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_md-3.7.0/ru_core_news_md-3.7.0-py3-none-any.whl (41.9 MB)\n",
      "     ---------------------------------------- 0.0/41.9 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/41.9 MB 991.0 kB/s eta 0:00:43\n",
      "     --------------------------------------- 0.1/41.9 MB 919.0 kB/s eta 0:00:46\n",
      "     ---------------------------------------- 0.2/41.9 MB 1.1 MB/s eta 0:00:37\n",
      "     ---------------------------------------- 0.3/41.9 MB 1.8 MB/s eta 0:00:24\n",
      "      --------------------------------------- 0.6/41.9 MB 2.5 MB/s eta 0:00:17\n",
      "      --------------------------------------- 1.0/41.9 MB 3.7 MB/s eta 0:00:12\n",
      "     - -------------------------------------- 1.3/41.9 MB 4.0 MB/s eta 0:00:11\n",
      "     - -------------------------------------- 1.7/41.9 MB 4.5 MB/s eta 0:00:10\n",
      "     -- ------------------------------------- 2.7/41.9 MB 6.3 MB/s eta 0:00:07\n",
      "     --- ------------------------------------ 3.8/41.9 MB 8.0 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 5.3/41.9 MB 10.2 MB/s eta 0:00:04\n",
      "     -------- ------------------------------- 9.1/41.9 MB 16.1 MB/s eta 0:00:03\n",
      "     ------------ -------------------------- 13.4/41.9 MB 65.2 MB/s eta 0:00:01\n",
      "     ----------------- --------------------- 19.0/41.9 MB 93.9 MB/s eta 0:00:01\n",
      "     ---------------------- --------------- 24.3/41.9 MB 110.0 MB/s eta 0:00:01\n",
      "     --------------------------- ---------- 29.9/41.9 MB 108.8 MB/s eta 0:00:01\n",
      "     -------------------------------- ----- 35.5/41.9 MB 108.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  41.2/41.9 MB 108.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  41.9/41.9 MB 131.2 MB/s eta 0:00:01\n",
      "     --------------------------------------- 41.9/41.9 MB 59.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in c:\\users\\vlad\\anaconda3\\lib\\site-packages (from ru-core-news-md==3.7.0) (3.7.4)\n",
      "Collecting pymorphy3>=1.0.0 (from ru-core-news-md==3.7.0)\n",
      "  Downloading pymorphy3-2.0.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting dawg-python>=0.7.1 (from pymorphy3>=1.0.0->ru-core-news-md==3.7.0)\n",
      "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting pymorphy3-dicts-ru (from pymorphy3>=1.0.0->ru-core-news-md==3.7.0)\n",
      "  Downloading pymorphy3_dicts_ru-2.4.417150.4580142-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\vlad\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\vlad\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\vlad\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\vlad\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\vlad\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\vlad\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\vlad\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\vlad\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\vlad\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\vlad\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (0.3.3)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\vlad\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\vlad\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\vlad\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (4.64.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\vlad\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (2.28.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\vlad\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (2.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vlad\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vlad\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (68.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vlad\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (22.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\vlad\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\vlad\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (1.23.5)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\vlad\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in c:\\users\\vlad\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\vlad\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\vlad\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vlad\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\vlad\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vlad\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (2023.5.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\vlad\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\vlad\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (0.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\vlad\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\vlad\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\vlad\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vlad\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (2.1.1)\n",
      "Downloading pymorphy3-2.0.1-py3-none-any.whl (53 kB)\n",
      "   ---------------------------------------- 0.0/53.2 kB ? eta -:--:--\n",
      "   ----------------------- ---------------- 30.7/53.2 kB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 53.2/53.2 kB 913.1 kB/s eta 0:00:00\n",
      "Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
      "Downloading pymorphy3_dicts_ru-2.4.417150.4580142-py2.py3-none-any.whl (8.4 MB)\n",
      "   ---------------------------------------- 0.0/8.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.1/8.4 MB 2.6 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.4/8.4 MB 4.6 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.0/8.4 MB 6.8 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.2/8.4 MB 6.5 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.3/8.4 MB 9.6 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 3.4/8.4 MB 12.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 5.7/8.4 MB 17.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.4/8.4 MB 23.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.4/8.4 MB 21.6 MB/s eta 0:00:00\n",
      "Installing collected packages: pymorphy3-dicts-ru, dawg-python, pymorphy3, ru-core-news-md\n",
      "Successfully installed dawg-python-0.7.2 pymorphy3-2.0.1 pymorphy3-dicts-ru-2.4.417150.4580142 ru-core-news-md-3.7.0\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('ru_core_news_md')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download ru_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "BvAU6NDimZe1"
   },
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "jsonObj = pd.read_json(path_or_buf='train.jsonl', lines=True)\n",
    "data = jsonObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_hwsLeqUBCAZ"
   },
   "outputs": [],
   "source": [
    "# Load the pre-trained Russian spaCy model\n",
    "nlp = ru_core_news_md.load()\n",
    "\n",
    "# Function to tokenize text and extract features\n",
    "def sent2features(sent):\n",
    "    doc = nlp(sent)\n",
    "    return [token2features(doc, i) for i in range(len(doc))]\n",
    "\n",
    "# Feature extraction\n",
    "def token2features(doc, i):\n",
    "    token = doc[i]\n",
    "    features = {\n",
    "        \"bias\": 1.0,\n",
    "        \"word.lower()\": token.text.lower(),\n",
    "        \"word[-3:]\": token.text[-3:],\n",
    "        \"word[-2:]\": token.text[-2:],\n",
    "        \"word.isupper()\": token.text.isupper(),\n",
    "        \"word.istitle()\": token.text.istitle(),\n",
    "        \"word.isdigit()\": token.text.isdigit(),\n",
    "        \"postag\": token.pos_,\n",
    "        \"postag[:2]\": token.pos_[:2],\n",
    "    }\n",
    "    # adding features for the previous token (if exists)\n",
    "    if i > 0:\n",
    "        prev_token = doc[i - 1]\n",
    "        features.update({\n",
    "            \"-1:word.lower()\": prev_token.text.lower(),\n",
    "            \"-1:word.istitle()\": prev_token.text.istitle(),\n",
    "            \"-1:word.isupper()\": prev_token.text.isupper(),\n",
    "            \"-1:postag\": prev_token.pos_,\n",
    "            \"-1:postag[:2]\": prev_token.pos_[:2],\n",
    "        })\n",
    "    else:\n",
    "        features[\"BOS\"] = True # indicator of the beginning of sentence\n",
    "\n",
    "    # adding features for the next token (if exists)\n",
    "    if i < len(doc) - 1:\n",
    "        next_token = doc[i + 1]\n",
    "        features.update({\n",
    "            \"+1:word.lower()\": next_token.text.lower(),\n",
    "            \"+1:word.istitle()\": next_token.text.istitle(),\n",
    "            \"+1:word.isupper()\": next_token.text.isupper(),\n",
    "            \"+1:postag\": next_token.pos_,\n",
    "            \"+1:postag[:2]\": next_token.pos_[:2],\n",
    "        })\n",
    "    else:\n",
    "        features[\"EOS\"] = True # indicator of the ending of sentence\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MhFxvzd2GFt6",
    "outputId": "cf4111cf-a941-4f5c-b866-b5a81b40dcd3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 519/519 [02:11<00:00,  3.96it/s]\n"
     ]
    }
   ],
   "source": [
    "# Generating features and labels\n",
    "labels_ = []\n",
    "features = []\n",
    "for idx, row in tqdm(data.iterrows(),total=data.shape[0]):\n",
    "  sentence = row.sentences\n",
    "  entities = row.ners\n",
    "  doc = nlp(sentence)\n",
    "  tokens = []\n",
    "  labels = ['O'] * len(doc) # default label\n",
    "  for start, end, label in entities:\n",
    "      for token in doc:\n",
    "          if token.idx == start:\n",
    "              labels[token.i] = 'B-' + label # beginning of entity\n",
    "          elif start < token.idx < end:\n",
    "              labels[token.i] = 'I-' + label # inside of entity\n",
    "  features.append(sent2features(sentence))\n",
    "  labels_.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "w5Eg2DB2Gjpw"
   },
   "outputs": [],
   "source": [
    "# Create a df for features and labels\n",
    "dataset = pd.DataFrame({'features': features, 'labels': labels_})\n",
    "X = dataset['features']\n",
    "y = dataset['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "TTxz5OyhM9iA"
   },
   "outputs": [],
   "source": [
    "# Splitting df into training and testing sets\n",
    "split = int(0.8 * len(X))\n",
    "X_train = X[:split]\n",
    "y_train = y[:split]\n",
    "X_test = X[split:]\n",
    "y_test = y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "AznQXb-XOJ0B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8431432565708364\n"
     ]
    }
   ],
   "source": [
    "# configuration of CRF model\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate of the performance\n",
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CRF(algorithm=&#x27;lbfgs&#x27;, all_possible_transitions=True, c1=0.1, c2=0.1,\n",
       "    max_iterations=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CRF</label><div class=\"sk-toggleable__content\"><pre>CRF(algorithm=&#x27;lbfgs&#x27;, all_possible_transitions=True, c1=0.1, c2=0.1,\n",
       "    max_iterations=100)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_transitions=True, c1=0.1, c2=0.1,\n",
       "    max_iterations=100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-train the model on the whole dataset\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rrCcCrwfQz86",
    "outputId": "93206e0a-94f0-484e-876d-a967639d8c58"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:12<00:00,  5.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# prediction on new test data (for submission)\n",
    "testObj = pd.read_json(path_or_buf='test_x.jsonl', lines=True)\n",
    "features_test = []\n",
    "for idx, row in tqdm(testObj.iterrows(),total=testObj.shape[0]):\n",
    "  sentence = row.senences\n",
    "  features_test.append(sent2features(sentence))\n",
    "X_pred = pd.DataFrame({'features': features_test})['features']\n",
    "y_pred = crf.predict(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "TnyslmQDQVoJ"
   },
   "outputs": [],
   "source": [
    "# constructing the final submission\n",
    "answers= []\n",
    "for i in range(len(y_pred)):\n",
    "  answer = []\n",
    "  for token, entity in zip(nlp(testObj.iloc[i].senences),y_pred[i]):\n",
    "    if entity[0]=='B':\n",
    "      i = token.idx\n",
    "      j = i + len(token.text) -1\n",
    "      answer.append([i,j,entity[2:]])\n",
    "    elif entity[0]=='I':\n",
    "      if len(answer)!=0:\n",
    "        j += len(token.text)+1\n",
    "        temp = answer[-1]\n",
    "        temp[1] = j\n",
    "        answer[-1] = temp\n",
    "      else:\n",
    "        i = token.idx\n",
    "        j = i + len(token.text)-1\n",
    "        answer.append([i,j,entity[2:]])\n",
    "  answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "M5J44g_QT4PD"
   },
   "outputs": [],
   "source": [
    "# Saving the submission\n",
    "submission = pd.DataFrame({'ners':answers, 'id':testObj.id})\n",
    "submission.to_json('test.jsonl',orient='records',lines=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
